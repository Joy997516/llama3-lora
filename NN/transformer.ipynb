{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "583f244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98328f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 4, 0, 0, 0],\n",
      "        [6, 6, 5, 2, 0]])\n",
      "tensor([[7, 6, 0, 0, 0],\n",
      "        [4, 4, 2, 7, 0]])\n"
     ]
    }
   ],
   "source": [
    "##word embedding\n",
    "##source sentence & targert sentence\n",
    "\n",
    "batch_size = 2\n",
    "##单词表大小\n",
    "max_num_src_words = 8\n",
    "max_num_tgt_words = 8\n",
    "\n",
    "##最大序列长度\n",
    "max_arc_seq_len = 5\n",
    "max_tgt_seq_len = 5\n",
    "\n",
    "#src_len = torch.randint(2, 5, (batch_size,))\n",
    "#tgt_len = torch.randint(2, 5, (batch_size,))\n",
    "##两个句子，第一个长度2，第二个长度4\n",
    "src_len = torch.Tensor([2,4]).to(torch.int32)\n",
    "tgt_len = torch.Tensor([4,3]).to(torch.int32)\n",
    "\n",
    "##单词索引序列\n",
    "##pad填充序列为统一最大长度，默认填充0\n",
    "##变为二维tensor\n",
    "src_seq = torch.cat([torch.unsqueeze(F.pad(torch.randint(1, max_num_src_words, (L,)),(0, max_arc_seq_len-L)),0)\n",
    "                                      for L in src_len])\n",
    "tgt_seq = torch.cat([torch.unsqueeze(F.pad(torch.randint(1, max_num_tgt_words, (L,)),(0, max_tgt_seq_len-L)), 0)\n",
    "                                      for L in src_len])\n",
    "print(src_seq)\n",
    "print(tgt_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeaabf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.2150, -0.2147, -0.6253, -0.3334, -1.0708, -1.6920, -1.1532, -0.3522],\n",
      "        [ 0.8549, -1.4145,  1.5203,  2.0198, -0.2876, -0.4578,  0.8444, -0.1299],\n",
      "        [ 0.9728,  1.7071,  1.9642,  0.0505, -2.1196,  1.0147,  0.4731,  0.7802],\n",
      "        [-1.4867,  0.4381,  1.1285, -0.9793,  0.2671,  0.5633,  0.0424,  0.3817],\n",
      "        [ 0.3047,  0.9499,  1.8239,  2.4549, -0.0083, -1.4732, -0.2489,  1.0262],\n",
      "        [ 0.4302,  0.1872, -0.0829, -1.4862, -0.8040,  0.8736, -1.5349, -1.1522],\n",
      "        [-0.3900, -1.6287,  0.2112, -0.2127,  0.2220,  0.1421,  2.6023,  0.0493],\n",
      "        [ 1.5544,  1.6540, -2.3084, -0.9239, -0.9263,  0.7701, -0.6956,  0.0987]],\n",
      "       requires_grad=True)\n",
      "tensor([[1, 4, 0, 0, 0],\n",
      "        [6, 6, 5, 2, 0]])\n",
      "tensor([[[ 0.8549, -1.4145,  1.5203,  2.0198, -0.2876, -0.4578,  0.8444,\n",
      "          -0.1299],\n",
      "         [ 0.3047,  0.9499,  1.8239,  2.4549, -0.0083, -1.4732, -0.2489,\n",
      "           1.0262],\n",
      "         [ 0.2150, -0.2147, -0.6253, -0.3334, -1.0708, -1.6920, -1.1532,\n",
      "          -0.3522],\n",
      "         [ 0.2150, -0.2147, -0.6253, -0.3334, -1.0708, -1.6920, -1.1532,\n",
      "          -0.3522],\n",
      "         [ 0.2150, -0.2147, -0.6253, -0.3334, -1.0708, -1.6920, -1.1532,\n",
      "          -0.3522]],\n",
      "\n",
      "        [[-0.3900, -1.6287,  0.2112, -0.2127,  0.2220,  0.1421,  2.6023,\n",
      "           0.0493],\n",
      "         [-0.3900, -1.6287,  0.2112, -0.2127,  0.2220,  0.1421,  2.6023,\n",
      "           0.0493],\n",
      "         [ 0.4302,  0.1872, -0.0829, -1.4862, -0.8040,  0.8736, -1.5349,\n",
      "          -1.1522],\n",
      "         [ 0.9728,  1.7071,  1.9642,  0.0505, -2.1196,  1.0147,  0.4731,\n",
      "           0.7802],\n",
      "         [ 0.2150, -0.2147, -0.6253, -0.3334, -1.0708, -1.6920, -1.1532,\n",
      "          -0.3522]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "##word embedding\n",
    "##embeding向量长度8\n",
    "model_dim = 8\n",
    "src_embedding_table = nn.Embedding(max_num_src_words,model_dim)\n",
    "tgt_embedding_table = nn.Embedding(max_num_tgt_words,model_dim)\n",
    "src_embedding = src_embedding_table(src_seq)\n",
    "tgt_embedding = tgt_embedding_table(tgt_seq)\n",
    "print(src_embedding_table.weight)\n",
    "print(src_seq)\n",
    "print(src_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61090b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3],\n",
      "        [0, 1, 2, 3]], dtype=torch.int32)\n",
      "tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "           1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
      "         [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n",
      "           9.9995e-01,  1.0000e-03,  1.0000e+00],\n",
      "         [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n",
      "           9.9980e-01,  2.0000e-03,  1.0000e+00],\n",
      "         [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n",
      "           9.9955e-01,  3.0000e-03,  1.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "           1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
      "         [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n",
      "           9.9995e-01,  1.0000e-03,  1.0000e+00],\n",
      "         [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n",
      "           9.9980e-01,  2.0000e-03,  1.0000e+00],\n",
      "         [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9995e-02,\n",
      "           9.9955e-01,  3.0000e-03,  1.0000e+00]]])\n"
     ]
    }
   ],
   "source": [
    "##position embedding\n",
    "max_position_len = 5\n",
    "pos_mat = torch.arange(max_position_len).reshape((-1,1))\n",
    "i_mat = torch.pow(10000,torch.arange(0, 8, 2).reshape(1,-1)/model_dim)\n",
    "pe_embedding_table = torch.zeros(max_position_len, model_dim)\n",
    "pe_embedding_table[:, 0::2] = torch.sin(pos_mat/i_mat)\n",
    "pe_embedding_table[:, 1::2] = torch.cos(pos_mat/i_mat)\n",
    "#print(pe_embedding_table)\n",
    "\n",
    "pe_embedding = nn.Embedding(max_position_len, model_dim)\n",
    "pe_embedding.weight = nn.Parameter(pe_embedding_table, requires_grad=False)\n",
    "#print(pe_embedding.weight)\n",
    "src_pos = torch.cat([torch.unsqueeze(torch.arange(max(src_len)),0) for _ in src_len]).to(torch.int32)\n",
    "print(src_pos)\n",
    "tgt_pos = torch.cat([torch.unsqueeze(torch.arange(max(tgt_len)),0) for _ in tgt_len]).to(torch.int32)\n",
    "\n",
    "src_pe_embedding = pe_embedding(src_pos)\n",
    "tgt_pe_embedding = pe_embedding(tgt_pos)\n",
    "print(src_pe_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50e11376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 6.6549e-01,  1.4553e-02, -1.0000e+09, -1.0000e+09],\n",
      "         [-1.7719e+00, -3.5355e-01, -1.0000e+09, -1.0000e+09],\n",
      "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09]],\n",
      "\n",
      "        [[ 1.2813e-01,  1.8046e-01, -1.3900e-01,  1.8591e+00],\n",
      "         [-8.6575e-01, -1.0751e+00, -1.1181e+00,  7.3859e-02],\n",
      "         [-1.3175e+00, -6.0572e-02, -9.1582e-01, -3.3958e+00],\n",
      "         [-4.0506e-01, -1.0690e+00, -9.1746e-01,  8.7240e-01]]])\n",
      "tensor([[[0.6572, 0.3428, 0.0000, 0.0000],\n",
      "         [0.1949, 0.8051, 0.0000, 0.0000],\n",
      "         [0.2500, 0.2500, 0.2500, 0.2500],\n",
      "         [0.2500, 0.2500, 0.2500, 0.2500]],\n",
      "\n",
      "        [[0.1181, 0.1245, 0.0904, 0.6670],\n",
      "         [0.1943, 0.1576, 0.1509, 0.4972],\n",
      "         [0.1630, 0.5730, 0.2436, 0.0204],\n",
      "         [0.1754, 0.0903, 0.1051, 0.6292]]])\n"
     ]
    }
   ],
   "source": [
    "##mask的shape:[batch_size,max_scr_len,max_scr_len],值为inf或1\n",
    "##先有效位再padding\n",
    "##batch为2扩一维Z\n",
    "valid_encoder_pos = torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L), (0, max(src_len)-L)),0) \\\n",
    "                                               for L in src_len]), 2)\n",
    "#print(valid_encoder_pos.shape)\n",
    "##三维矩阵相乘\n",
    "valid_encorder_pos_matrix = torch.bmm(valid_encoder_pos, valid_encoder_pos.transpose(1,2))\n",
    "##相当于邻接矩阵\n",
    "#print(valid_encorder_pos_matrix)\n",
    "#print(src_len)\n",
    "\n",
    "invalid_encorder_pos_matrix = 1 - valid_encorder_pos_matrix\n",
    "#print(invalid_encorder_pos_matrix)\n",
    "\n",
    "##true就mask\n",
    "mask_encoder_self_attention = invalid_encorder_pos_matrix.to(torch.bool)\n",
    "#print(mask_encoder_self_attention)\n",
    "\n",
    "score = torch .randn(batch_size, max(src_len), max(src_len))\n",
    "##为0部分fill -1e9\n",
    "masked_score = score.masked_fill(mask_encoder_self_attention, -1e9)\n",
    "prob = F.softmax(masked_score, -1)\n",
    "\n",
    "#print(score)\n",
    "#print(src_len)\n",
    "print(masked_score)\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5991db85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[False, False,  True,  True],\n",
      "         [False, False,  True,  True],\n",
      "         [False, False,  True,  True],\n",
      "         [False, False,  True,  True]],\n",
      "\n",
      "        [[False, False, False, False],\n",
      "         [False, False, False, False],\n",
      "         [False, False, False, False],\n",
      "         [ True,  True,  True,  True]]])\n"
     ]
    }
   ],
   "source": [
    "#intra-attention的mask\n",
    "##Q @ K^T shape:[batch,tgt_seq_len, src_seq_len]\n",
    "valid_decoder_pos = torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L), (0, max(tgt_len)-L)),0) \\\n",
    "                                               for L in tgt_len]), 2)\n",
    "##scr与tgt有效性\n",
    "valid_cross_pos_matrix = torch.bmm(valid_decoder_pos, valid_encoder_pos.transpose(1,2))\n",
    "#print(valid_encoder_pos)\n",
    "#print(valid_decoder_pos)\n",
    "#print(valid_cross_pos)\n",
    "invalid_cross_pos_matrix = 1 - valid_cross_pos_matrix\n",
    "mask_cross_attention = invalid_cross_pos_matrix.to(torch.bool)\n",
    "#print(mask_cross_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "918ae5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.6193, 0.3807, 0.0000, 0.0000],\n",
      "         [0.4531, 0.2043, 0.3426, 0.0000],\n",
      "         [0.1401, 0.1951, 0.2347, 0.4301]],\n",
      "\n",
      "        [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.1941, 0.8059, 0.0000, 0.0000],\n",
      "         [0.1540, 0.5431, 0.3029, 0.0000],\n",
      "         [0.2500, 0.2500, 0.2500, 0.2500]]])\n"
     ]
    }
   ],
   "source": [
    "##decorder self-attention的mask(三角)\n",
    "valid_decoder_tri_matrix = torch.cat([torch.unsqueeze(F.pad(torch.tril(torch.ones(L,L)), \\\n",
    "                                                            (0,max(tgt_len)-L,0,max(tgt_len)-L)),0) \\\n",
    "                                      for L in tgt_len])\n",
    "#print(valid_decoder_tri_matrix)\n",
    "#print(valid_decoder_tri_matrix.shape)\n",
    "invalid_decoder_tri_matrix = 1-valid_decoder_tri_matrix\n",
    "invalid_decoder_tri_matrix = invalid_decoder_tri_matrix.to(torch.bool)\n",
    "#print(invalid_decoder_tri_matrix)\n",
    "score = torch .randn(batch_size, max(tgt_len), max(tgt_len))\n",
    "##为0部分fill -1e9\n",
    "masked_score = score.masked_fill(invalid_decoder_tri_matrix, -1e9)\n",
    "prob = F.softmax(masked_score, -1)\n",
    "#print(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "00bd69d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##self-attention\n",
    "##shape of Q,K,V : (batch_size*num_head, seq_len,model_dim/num_head)\n",
    "def scaled_dot_product_attention(Q,K,V,attn_mask):\n",
    "    score = torch.bmm(Q,K,transpose(-2,-1))/torch.sqrt(model_dim)\n",
    "    masked_score = score.masked_fill(attn_mask, -1e9)\n",
    "    prob = F.softmax(masked_score, -1)\n",
    "    context = torch.bmm(prob,V)\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5eed2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a336fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
