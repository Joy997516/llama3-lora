{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e68e3936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9313bdbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0467, -0.2262,  0.1009,  0.0181, -0.4716],\n",
      "         [ 0.0770, -0.1335, -0.0828,  0.1359, -0.2228],\n",
      "         [ 0.1128, -0.1604, -0.1379,  0.4182,  0.0183]],\n",
      "\n",
      "        [[ 0.4830,  0.3796,  0.0830, -0.0610, -0.0134],\n",
      "         [ 0.0589,  0.2820, -0.1063, -0.1542, -0.1215],\n",
      "         [ 0.0594,  0.1878, -0.1361, -0.1986, -0.1460]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[[ 0.1128, -0.1604, -0.1379,  0.4182,  0.0183],\n",
      "         [ 0.0594,  0.1878, -0.1361, -0.1986, -0.1460]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "tensor([[[ 0.3187, -0.3272, -0.3735,  0.6051,  0.0393],\n",
      "         [ 0.1298,  0.4271, -0.2945, -0.3860, -0.2693]]],\n",
      "       grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "bs, T, i_size, h_size = 2, 3, 4, 5\n",
    "input = torch.randn(bs, T, i_size)\n",
    "c0 = torch.randn(bs, h_size)\n",
    "h0 = torch.randn(bs,h_size)\n",
    "\n",
    "lstm_layer = nn.LSTM(i_size, h_size, batch_first = True)\n",
    "output, (hn, cn) = lstm_layer(input, (h0.unsqueeze(0) ,c0.unsqueeze(0)))\n",
    "print(output)\n",
    "print(hn)\n",
    "print(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117861e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0 Parameter containing:\n",
      "tensor([[ 0.4169, -0.0408,  0.2963, -0.3897],\n",
      "        [ 0.2836, -0.2703, -0.3928,  0.3190],\n",
      "        [ 0.0222,  0.1646,  0.3935, -0.3035],\n",
      "        [ 0.3735, -0.4393, -0.3617, -0.3809],\n",
      "        [ 0.3914,  0.0273,  0.3561, -0.1903],\n",
      "        [-0.2129,  0.3855,  0.3294, -0.4384],\n",
      "        [ 0.1983,  0.1146, -0.2064,  0.3244],\n",
      "        [-0.0149,  0.0017,  0.1221,  0.0919],\n",
      "        [ 0.2423,  0.4331, -0.0146,  0.0933],\n",
      "        [ 0.0081, -0.1136,  0.1429,  0.2141],\n",
      "        [-0.1832,  0.0664, -0.1759,  0.2322],\n",
      "        [ 0.0890, -0.1788,  0.2994, -0.2285],\n",
      "        [-0.1244, -0.1792,  0.2920,  0.1311],\n",
      "        [-0.4446,  0.2604, -0.1670, -0.1984],\n",
      "        [-0.1053,  0.2581, -0.2646, -0.1538],\n",
      "        [-0.1556, -0.4160,  0.0323,  0.3732],\n",
      "        [-0.2581, -0.0085,  0.3566, -0.2454],\n",
      "        [ 0.3432, -0.0930, -0.1764, -0.0991],\n",
      "        [-0.3629,  0.3339, -0.3523,  0.4205],\n",
      "        [ 0.0654,  0.1552,  0.1192,  0.0624]], requires_grad=True)\n",
      "weight_ih_l0 torch.Size([20, 4])\n",
      "weight_hh_l0 Parameter containing:\n",
      "tensor([[ 0.2520,  0.2862, -0.1275,  0.3497, -0.0470],\n",
      "        [ 0.2378, -0.0781, -0.1937,  0.2012, -0.3548],\n",
      "        [ 0.1459,  0.2905, -0.4458,  0.3798,  0.2821],\n",
      "        [-0.2674,  0.2158, -0.3684,  0.0915, -0.4416],\n",
      "        [ 0.1837,  0.2300, -0.4277,  0.0942, -0.3813],\n",
      "        [-0.3166, -0.2044, -0.2116,  0.2945, -0.1055],\n",
      "        [ 0.2658, -0.1538,  0.0908,  0.2158, -0.2870],\n",
      "        [ 0.0985,  0.3248,  0.2105,  0.1269, -0.3570],\n",
      "        [-0.0887,  0.4444, -0.3916, -0.1827, -0.3758],\n",
      "        [-0.3209,  0.1573,  0.0232, -0.1020,  0.2282],\n",
      "        [ 0.2573, -0.3109,  0.3294,  0.0823, -0.1838],\n",
      "        [-0.3986,  0.1701, -0.3839,  0.3978, -0.4021],\n",
      "        [ 0.2847,  0.0976,  0.0273,  0.2421,  0.3816],\n",
      "        [ 0.3056, -0.4354,  0.3632, -0.4386,  0.1177],\n",
      "        [-0.1210,  0.0097,  0.3769, -0.2383, -0.3539],\n",
      "        [-0.4036, -0.2139,  0.0587, -0.1599, -0.1616],\n",
      "        [ 0.1730,  0.0327,  0.0181, -0.0201,  0.1052],\n",
      "        [ 0.1173,  0.0712, -0.3240, -0.0963, -0.0799],\n",
      "        [ 0.4199,  0.2496,  0.0440,  0.0459, -0.2535],\n",
      "        [-0.0337,  0.1131, -0.3350,  0.3887, -0.2567]], requires_grad=True)\n",
      "weight_hh_l0 torch.Size([20, 5])\n",
      "bias_ih_l0 Parameter containing:\n",
      "tensor([-0.2717, -0.2698, -0.3784, -0.0097, -0.2632, -0.3238,  0.3661, -0.4122,\n",
      "         0.2853, -0.1055, -0.0582,  0.2348, -0.0123,  0.0588, -0.2958,  0.0418,\n",
      "        -0.0796, -0.2050,  0.3601, -0.0067], requires_grad=True)\n",
      "bias_ih_l0 torch.Size([20])\n",
      "bias_hh_l0 Parameter containing:\n",
      "tensor([ 0.3833,  0.0377,  0.3436, -0.3011,  0.1853,  0.0871, -0.3222,  0.1218,\n",
      "        -0.0879,  0.1046,  0.3189, -0.1787, -0.3651,  0.2010,  0.1625, -0.1575,\n",
      "         0.1967, -0.1948, -0.1470,  0.0867], requires_grad=True)\n",
      "bias_hh_l0 torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "for k, v in lstm_layer.named_parameters():\n",
    "    print(k, v)\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc718de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##i_s元组（h0,c0）\n",
    "def lstm_forward(input, i_s,w_ih, w_hh, b_ih, b_hh):\n",
    "    h0, c0 = i_s\n",
    "    bs, T, input_size = input.shape\n",
    "    h_size = w_ih.shape[0]//4\n",
    "    \n",
    "    prev_h = h0\n",
    "    prev_c = c0\n",
    "    output_size = h_size\n",
    "    output = torch.zeros(bs, T, output_size)\n",
    "    \n",
    "    #w_ih [4*h_size, i_size] w_hh [4*h_size, h_size]\n",
    "    w_ih_batch = w_ih.unsqueeze(0).tile(bs, 1, 1) \n",
    "    w_hh_batch = w_hh.unsqueeze(0).tile(bs, 1, 1) \n",
    "    for t in range(T):\n",
    "        x = input[:, t ,:] ##batch_size,t,input_size\n",
    "        w_times_x = torch.bmm(w_ih_batch, x.unsqueeze(-1)) #扩[bs, 4*h_size, 1]\n",
    "        w_times_x = w_times_x.squeeze(-1) #[bs, 4*h_size]\n",
    "        w_times_h_prev = torch.bmm(w_hh_batch, prev_h.unsqueeze(-1))\n",
    "        w_times_h_prev = w_times_h_prev.squeeze(-1)\n",
    "        \n",
    "        ##输入门（i）,遗忘门(f), cell门(g), 输出门(o)\n",
    "        i_t = torch.sigmoid(w_times_x[:, :h_size]+ w_times_h_prev[:, :h_size] + b_ih[:h_size] +b_hh[:h_size])\n",
    "        f_t = torch.sigmoid(w_times_x[:, h_size:2*h_size]+ w_times_h_prev[:, h_size:2*h_size] + b_ih[h_size:2*h_size] +b_hh[h_size:2*h_size])\n",
    "        g_t = torch.tanh(w_times_x[:, 2*h_size:3*h_size]+ w_times_h_prev[:, 2*h_size:3*h_size] + b_ih[2*h_size:3*h_size] +b_hh[2*h_size:3*h_size])\n",
    "        o_t = torch.sigmoid(w_times_x[:, 3*h_size:4*h_size]+ w_times_h_prev[:, 3*h_size:4*h_size] + b_ih[3*h_size:4*h_size] +b_hh[3*h_size:4*h_size])\n",
    "        prev_c = f_t*prev_c + i_t * g_t\n",
    "        prev_h = o_t * torch.tanh(prev_c)\n",
    "        output[:, t, :] = prev_h\n",
    "    return output, (prev_h, prev_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4194f6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0467, -0.2262,  0.1009,  0.0181, -0.4716],\n",
       "          [ 0.0770, -0.1335, -0.0828,  0.1359, -0.2228],\n",
       "          [ 0.1128, -0.1604, -0.1379,  0.4182,  0.0183]],\n",
       " \n",
       "         [[ 0.4830,  0.3796,  0.0830, -0.0610, -0.0134],\n",
       "          [ 0.0589,  0.2820, -0.1063, -0.1542, -0.1215],\n",
       "          [ 0.0594,  0.1878, -0.1361, -0.1986, -0.1460]]], grad_fn=<CopySlices>),\n",
       " (tensor([[ 0.1128, -0.1604, -0.1379,  0.4182,  0.0183],\n",
       "          [ 0.0594,  0.1878, -0.1361, -0.1986, -0.1460]], grad_fn=<MulBackward0>),\n",
       "  tensor([[ 0.3187, -0.3272, -0.3735,  0.6051,  0.0393],\n",
       "          [ 0.1298,  0.4271, -0.2945, -0.3860, -0.2693]], grad_fn=<AddBackward0>)))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_forward(input, (h0, c0), lstm_layer.weight_ih_l0, lstm_layer.weight_hh_l0, lstm_layer.bias_ih_l0, lstm_layer.bias_hh_l0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e9ee159",
   "metadata": {},
   "outputs": [],
   "source": [
    "quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc93bc91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
